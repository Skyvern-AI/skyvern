---
title: Self-Hosted Overview
subtitle: Run Skyvern on your own infrastructure
slug: self-hosted/overview
---

Self-hosted Skyvern runs entirely on your infrastructure—your servers, your browsers, your LLM API keys. This guide helps you decide if self-hosting fits your needs and which deployment method to choose.

## When to self-host

- **Data privacy** — Browser sessions and extracted data never leave your network
- **Compliance requirements** — Meet SOC 2, HIPAA, or internal security policies that prohibit third-party data processing
- **Air-gapped environments** — Run in isolated networks using local LLMs via Ollama
- **High volume** — Avoid per-task pricing when running thousands of automations
- **Custom models** — Use fine-tuned or proprietary LLMs through any OpenAI-compatible endpoint

## Architecture

Self-hosted Skyvern has four components running on your infrastructure:

```mermaid
flowchart LR
    subgraph Your Infrastructure
        API[Skyvern API Server]
        DB[(PostgreSQL)]
        Browser[Browser Container]
    end

    LLM[LLM Provider]
    Sites[Target Websites]

    API <--> DB
    API <--> Browser
    API <--> LLM
    Browser <--> Sites
```

| Component | Role |
|-----------|------|
| **Skyvern API Server** | Orchestrates tasks, processes LLM responses, stores results |
| **PostgreSQL** | Stores task history, workflows, credentials, and organization data |
| **Browser Container** | Playwright-managed Chromium that executes the actual web automation |
| **LLM Provider** | Analyzes screenshots and determines actions—you provide the API key (OpenAI, Anthropic, Azure, or local via Ollama) |

The browser and LLM are separate services. Skyvern captures screenshots from the browser, sends them to the LLM for analysis, receives action instructions, and executes them in the browser. This loop continues until the task completes.

## What changes from Cloud

| You gain | You manage |
|----------|------------|
| Full data control—browser sessions and results stay on your network | Infrastructure—servers, scaling, uptime |
| Any LLM provider, including local models via Ollama | LLM API costs—pay your provider directly |
| No per-task pricing | Proxies—Cloud includes managed residential proxies; self-hosted requires your own |
| Full access to browser configuration and extensions | Software updates—pull new Docker images manually |
| Deploy in air-gapped or restricted networks | Database backups and maintenance |

<Note>
The most significant operational difference is **proxies**. Skyvern Cloud routes browser traffic through managed residential proxies to avoid bot detection. Self-hosted deployments need you to configure your own proxy provider.
</Note>

## Prerequisites

Before deploying, ensure you have:

<Steps>
  <Step title="Docker and Docker Compose">
    Required for containerized deployment. [Install Docker](https://docs.docker.com/get-docker/)
  </Step>
  <Step title="4GB+ RAM">
    Browser instances are memory-intensive. Production deployments benefit from 8GB+.
  </Step>
  <Step title="LLM API key">
    From OpenAI, Anthropic, Azure OpenAI, Google Gemini, or AWS Bedrock. Alternatively, run local models with Ollama.
  </Step>
  <Step title="Proxy provider (recommended)">
    For automating external websites at scale. Not required for internal tools or development.
  </Step>
</Steps>

PostgreSQL 14+ is included in the Docker Compose setup. If you prefer an external database, you can configure `DATABASE_STRING` to point to your own instance.

## Choose your deployment method

| Method | Best for |
|--------|----------|
| **Docker Compose** | Getting started, small teams, single-server deployments |
| **Kubernetes** | Production at scale, teams with existing K8s infrastructure, high availability requirements |
| **Local (no containers)** | Development, debugging, testing prompts before deploying |

Most teams start with Docker Compose—it's the fastest path to a working deployment. Move to Kubernetes when you need horizontal scaling or want to integrate with existing orchestration infrastructure.

## Next steps

<CardGroup cols={2}>
  <Card title="Docker Setup" icon="docker" href="/self-hosted/docker">
    Get Skyvern running in 10 minutes with Docker Compose
  </Card>
  <Card title="Kubernetes Deployment" icon="dharmachakra" href="/self-hosted/kubernetes">
    Deploy to production with Kubernetes manifests
  </Card>
</CardGroup>
